{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s-8ltYHfbs5B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "\n",
        "from typing import List, Dict\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "UHYJhYYOTnie",
        "outputId": "5c2c60c7-7d4b-438e-f514-1e1d13f3d3c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tqZpPvvyluyu7VVvk99tKpJd4cIkS4yi\n",
            "To: /Users/malikchettih/Projects/Emiasd-Projects/Emiasd-NLP/02.TP/IMDB_Dataset.csv\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66.2M/66.2M [00:01<00:00, 43.8MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'IMDB_Dataset.csv'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "google_path = \"https://drive.google.com/uc?id=\"\n",
        "file_id = \"1tqZpPvvyluyu7VVvk99tKpJd4cIkS4yi\"\n",
        "output_name = \"IMDB_Dataset.csv\"\n",
        "gdown.download(google_path + file_id, output_name, quiet=False, resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxPeSF1dTnif"
      },
      "source": [
        "# Introduction : Machine learning for NLP\n",
        "\n",
        "üöß **Question** üöß\n",
        "\n",
        "Why would one need NLP?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxtv1thiTnig"
      },
      "source": [
        "üöß **Question** üöß\n",
        "\n",
        "Can you give two main domain of NLP applications?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4KtqqRwTnih"
      },
      "source": [
        "### First application: text classification\n",
        "\n",
        "- Goal of text classification: assign a label to a text.\n",
        "- We actually want to model $p(y | x)$ where $x$ is the text and $y$ is the label.\n",
        "- Let's call $\\hat{p}$ our model. $\\hat{p}$ is a function that takes a text as input and outputs a label.\n",
        "\n",
        "üöß **Question** üöß\n",
        "\n",
        "How would you model $\\hat{p}$?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDGkIpBFTnih"
      },
      "source": [
        "# From Raw data to dataset\n",
        "First take a look at the data !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "y_Mj2VX4Tnii",
        "outputId": "7a1a8f81-aeea-4abf-84ca-b96c0ad0b200",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.&lt;br /&gt;&lt;br /&gt;The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.&lt;br /&gt;&lt;br /&gt;We wish Mr. Mattei good luck and await anxiously for his next work.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              review  \\\n",
              "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                              Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.   \n",
              "\n",
              "  sentiment  \n",
              "0  positive  \n",
              "1  positive  \n",
              "2  positive  \n",
              "3  negative  \n",
              "4  positive  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(output_name, nrows=5000)\n",
        "# Print some data. Make sure all text is printed with pandas, with word wrap\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsXN_LpLTnii"
      },
      "source": [
        "We need input and output: $X$ and $y$.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dqX_Z8FGTnij"
      },
      "outputs": [],
      "source": [
        "X = df[\"review\"]\n",
        "y = (df[\"sentiment\"] == \"positive\").astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOEng4QKTnil"
      },
      "source": [
        "## Split train and test (and validation)\n",
        "\n",
        "üöß **Question** üöß\n",
        "\n",
        "It is important to do it before the preprocessing. Why now ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VzWiuSATTnil"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=1234\n",
        ")\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-d89CClTnil",
        "outputId": "b9133eea-8583-41b0-f8da-5a9e936e1100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This movie starts off on the wrong foot and never really gets it going. The first scene shows a Life Flight helicopter landing and just outside the window you can distinctly see mountains in the background. For those of you who might not ever have been to Houston there is no elevation change. The city sits just above sea level and a 5 ft. incline is considered a big hill. To go along with that scenery, any shots outside of the hospital immediately tell the viewer that they are not in Houston. The trees are all missing leaves or are pine trees, neither of which Houston has very much of. Even the hospital itself, on the outside, is very unbelievable. Memorial Hermann Hospital is one of the top hospitals in the United States and sits smack dab in the middle of the Medical District just miles from downtown Houston, yet every outside shot of the hospital makes it appear that the hospital is out in the suburbs or even the countryside.<br /><br />It is obvious that whoever was in charge of the actual tropical storm part of the movie skimped out because the numerous shots of radar are all wrong. The first radar image in the movie is that of Hurrican Hugo hitting South Carolina. We later see Kris Kristofferson leaving his job and one of his assistants tells him that Alison is moving back south across Houston yet the radar image he shows has Alison clearly moving north off of the Gulf of Mexico into Houston...probably the initial landfall of Alison.<br /><br />As for the acting, it isn't all that bad. JoBeth Williams, Kris Kristofferson and Rick Schroder all do a decent job considering that this is a straight-to-TV movie. The plot of the story is decent and the fact that it is based on a true story makes it a bit more entertaining. My one problem with the acting is the portrayal of Houstonians with big thick Southern accents...the actors all sound like they are from Birmingham, Alabama and not Houston, Texas.<br /><br />The movie gets its point across and to the general audience it does exactly what it is meant to: entertain. If you are looking for a factual account of what happened to the city of Houston in June of 2001 then you will be disappointed. One thing to keep in mind before viewing this movie is that it is based solely on the evacuation of Memorial Hermann Hospital and not on Tropical Storm Alison and the impact on Houston metro itself. If you are looking for a factual account of Tropical Storm Alison's impact on Houston metro might I suggest watching The Weather Channel's Storm Stories for Tropical Storm Alison.<br /><br />*1/2 out of *****\n",
            "\n",
            "This music is totally out of touch with the film, showing up now and then as wagnerian bombast and Lone Ranger hurry-up, otherwise nonexistent. The acting, outside of the two principals, is nonexistent. It would have been an excellent student film. The Russian soldiers are just models trying to act. The constant interruptions with wow-explosive-camera angles and monocolor clips of pieces of people were quite irritating, but that's just a personal feeling. The story line isn't worse than others, actually not worse than most, completely ignoring logic and reason and reality. At least nobody walked in front of a machine gun for three minutes without being hit. The three top-level bad guys were campy.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Explore a couple of input texts\n",
        "n = 2\n",
        "selection = np.random.choice(len(X_train), n)\n",
        "for i in selection:\n",
        "    print(X_train[i] + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ytn0MjoTnil"
      },
      "source": [
        "üöß **Question** üöß\n",
        "\n",
        "Is it what we want  ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-52EVGjTnin"
      },
      "source": [
        "##¬†Pre-processing and Tokenization\n",
        "\n",
        "Tokenizing a text means splitting it into words.\n",
        "\n",
        "This is not as easy as it seems. For instance, how would you tokenize the following text?\n",
        "\n",
        "```\n",
        "I'm a student. Are you a student? Alex's course has already started!\n",
        "```\n",
        "- We can naively split on spaces.\n",
        "- We can use a library like `nltk`, that incorporates more rules to split the text (`spacy`, `beautiful soup`)\n",
        "- We can include some *pre-processing*.\n",
        "- Deal with encoding issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1iYgyFYZTnin"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-uuU1v4ZTnin"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text: str) -> str:\n",
        "    # lower case\n",
        "    text = text.lower()\n",
        "    # string normalization.\n",
        "    text = unicodedata.normalize(\"NFD\", text).encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    # replace remove html stuffs.\n",
        "    text = re.sub(\"<.*?>\", \" \", text)\n",
        "\n",
        "    # remove non alpha numeric character, e.g punctuations !\n",
        "    text = re.sub(\"[^a-z0-9]\", \" \", text)\n",
        "\n",
        "    # replace numbers by the <NUM> token.\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "\n",
        "    # remove double whitespaces.\n",
        "    text = re.sub(\" +\", \" \", text.strip())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5BCntyxVTnin",
        "outputId": "a044b4c8-c6db-43b4-f91e-05b4184549df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i lived in san francisco for years'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noisy_text = \"√è   l√Æved  in    San-Fran√ßisco...  ! for <bf>12 years</bf>.\"\n",
        "preprocess_text(noisy_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiTm1_UXTnin",
        "outputId": "7430349b-de48-47e0-d8cc-e90d4ec69998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this movie starts off on the wrong foot and never really gets it going the first scene shows a life flight helicopter landing and just outside the window you can distinctly see mountains in the background for those of you who might not ever have been to houston there is no elevation change the city sits just above sea level and a ft incline is considered a big hill to go along with that scenery any shots outside of the hospital immediately tell the viewer that they are not in houston the trees are all missing leaves or are pine trees neither of which houston has very much of even the hospital itself on the outside is very unbelievable memorial hermann hospital is one of the top hospitals in the united states and sits smack dab in the middle of the medical district just miles from downtown houston yet every outside shot of the hospital makes it appear that the hospital is out in the suburbs or even the countryside it is obvious that whoever was in charge of the actual tropical storm part of the movie skimped out because the numerous shots of radar are all wrong the first radar image in the movie is that of hurrican hugo hitting south carolina we later see kris kristofferson leaving his job and one of his assistants tells him that alison is moving back south across houston yet the radar image he shows has alison clearly moving north off of the gulf of mexico into houston probably the initial landfall of alison as for the acting it isn t all that bad jobeth williams kris kristofferson and rick schroder all do a decent job considering that this is a straight to tv movie the plot of the story is decent and the fact that it is based on a true story makes it a bit more entertaining my one problem with the acting is the portrayal of houstonians with big thick southern accents the actors all sound like they are from birmingham alabama and not houston texas the movie gets its point across and to the general audience it does exactly what it is meant to entertain if you are looking for a factual account of what happened to the city of houston in june of then you will be disappointed one thing to keep in mind before viewing this movie is that it is based solely on the evacuation of memorial hermann hospital and not on tropical storm alison and the impact on houston metro itself if you are looking for a factual account of tropical storm alison s impact on houston metro might i suggest watching the weather channel s storm stories for tropical storm alison out of\n",
            "\n",
            "this music is totally out of touch with the film showing up now and then as wagnerian bombast and lone ranger hurry up otherwise nonexistent the acting outside of the two principals is nonexistent it would have been an excellent student film the russian soldiers are just models trying to act the constant interruptions with wow explosive camera angles and monocolor clips of pieces of people were quite irritating but that s just a personal feeling the story line isn t worse than others actually not worse than most completely ignoring logic and reason and reality at least nobody walked in front of a machine gun for three minutes without being hit the three top level bad guys were campy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.apply(preprocess_text)\n",
        "X_test = X_test.apply(preprocess_text)\n",
        "\n",
        "for i in selection:\n",
        "    print(X_train[i] + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJS2AYYpTnin"
      },
      "source": [
        "**And the tokenizer ?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Oe457kTnin"
      },
      "source": [
        "üöß **Question** üöß\n",
        "\n",
        "How to do a simple \"White Space\" tokenizer ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9Xb6DtTMTnio",
        "outputId": "dbe58c6d-a946-4161-aa4d-87cdd10443b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'm',\n",
              " 'a',\n",
              " 'student',\n",
              " 'are',\n",
              " 'you',\n",
              " 'a',\n",
              " 'student',\n",
              " 'alex',\n",
              " 's',\n",
              " 'course',\n",
              " 'has',\n",
              " 'already',\n",
              " 'started']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try simple code\n",
        "# Test it on sample sentences.\n",
        "\n",
        "testsentence = \"I'm a student. Are you a student? Alex's course has already started!\"\n",
        "preprocess_text(testsentence).split(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSAcNSU3Tnio"
      },
      "source": [
        "In a more useful way, a tokenizer should be able to:\n",
        "- tokenize string\n",
        "- build a vocabulary\n",
        "- maybe keep track of word frequencies\n",
        "- build a natural text from its tokenized version.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XviiFnuZTnio",
        "outputId": "c58afae0-1206-4456-da1f-6a13f9fb2fb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/malikchettih/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt_tab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ybvIKIijTnip"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "\n",
        "class WhiteSpaceTokenizer:\n",
        "    def __init__(self):\n",
        "        # The vocabulary will store the mapping between text tokens and their id.\n",
        "        self.vocab = {}\n",
        "        self.id_to_token = {}\n",
        "\n",
        "        # We will keep track of the number of ties a word appears in the corpus.\n",
        "        self.frequencies = {}\n",
        "\n",
        "    def split_text(self, text: str) -> List[str]:\n",
        "        \"\"\"Converts the text to a list of tokens (substrings).\"\"\"\n",
        "        return word_tokenize(text)\n",
        "\n",
        "    def encode(self, text: str) -> List[int]:\n",
        "        \"\"\"Take a text as input and return its associated tokenization, as a list of ids.\"\"\"\n",
        "        list_tokens = self.split_text(text)\n",
        "        list_ids = []\n",
        "        for token in list_tokens:\n",
        "            list_ids.append(self.vocab.get(token, -1))\n",
        "        return list_ids\n",
        "\n",
        "    def decode(self, ids: List[int]) -> str:\n",
        "        tokens = [self.id_to_token[i] for i in ids]\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "    def fit(self, corpus: List[str]):\n",
        "        \"\"\"Fits the tokenizer to a list of texts to construct its vocabulary.\"\"\"\n",
        "        current_id = 0\n",
        "        for text in corpus:\n",
        "            list_tokens = self.split_text(text)\n",
        "            for token in list_tokens:\n",
        "                token_id = self.vocab.get(token, None)\n",
        "                if token_id is None:\n",
        "                    self.vocab[token] = current_id\n",
        "                    self.id_to_token[current_id] = token\n",
        "                    self.frequencies[current_id] = 0\n",
        "                    token_id = current_id\n",
        "                    current_id += 1\n",
        "\n",
        "                self.frequencies[token_id] += 1\n",
        "        self.num_words = current_id\n",
        "        self.vocab[\"<UNK>\"] = -1\n",
        "        self.id_to_token[-1] = \"<UNK>\"\n",
        "        print(f\"Built a vocabulary of {self.num_words} words.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmxF3aD2Tniq",
        "outputId": "ca698e50-feef-4b00-a1c9-afebe4b57274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built a vocabulary of 32830 words.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = WhiteSpaceTokenizer()\n",
        "tokenizer.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ow1T8qRLTniq",
        "outputId": "0ef21cbb-03b2-4299-e037-71693a97ce36",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'i': 0,\n",
              " 'mean': 1,\n",
              " 'really': 2,\n",
              " 'this': 3,\n",
              " 'is': 4,\n",
              " 'not': 5,\n",
              " 'going': 6,\n",
              " 'to': 7,\n",
              " 'help': 8,\n",
              " 'the': 9,\n",
              " 'australian': 10,\n",
              " 'film': 11,\n",
              " 'industry': 12,\n",
              " 'make': 13,\n",
              " 'kind': 14,\n",
              " 'of': 15,\n",
              " 'with': 16,\n",
              " 'no': 17,\n",
              " 'values': 18,\n",
              " 'any': 19,\n",
              " 'okay': 20,\n",
              " 'if': 21,\n",
              " 'you': 22,\n",
              " 're': 23,\n",
              " 'a': 24,\n",
              " 'stoner': 25,\n",
              " 'and': 26,\n",
              " 'have': 27,\n",
              " 'nothing': 28,\n",
              " 'better': 29,\n",
              " 'do': 30,\n",
              " 'then': 31,\n",
              " 'maybe': 32,\n",
              " 'think': 33,\n",
              " 'makers': 34,\n",
              " 'from': 35,\n",
              " 'here': 36,\n",
              " 'should': 37,\n",
              " 'try': 38,\n",
              " 'show': 39,\n",
              " 'rest': 40,\n",
              " 'world': 41,\n",
              " 'what': 42,\n",
              " 'great': 43,\n",
              " 'talented': 44,\n",
              " 'people': 45,\n",
              " 'we': 46,\n",
              " 'vehicle': 47,\n",
              " 'for': 48,\n",
              " 'it': 49,\n",
              " 'come': 50,\n",
              " 'on': 51,\n",
              " 'now': 52,\n",
              " 'just': 53,\n",
              " 'tacky': 54,\n",
              " 'll': 55,\n",
              " 'give': 56,\n",
              " 'writer': 57,\n",
              " 'director': 58,\n",
              " 'william': 59,\n",
              " 'gove': 60,\n",
              " 'credit': 61,\n",
              " 'finding': 62,\n",
              " 'someone': 63,\n",
              " 'finance': 64,\n",
              " 'ill': 65,\n",
              " 'conceived': 66,\n",
              " 'thriller': 67,\n",
              " 'good': 68,\n",
              " 'argument': 69,\n",
              " 'wasting': 70,\n",
              " 'money': 71,\n",
              " 'subscribing': 72,\n",
              " 'hbo': 73,\n",
              " 'let': 74,\n",
              " 'alone': 75,\n",
              " 'buying': 76,\n",
              " 'dvds': 77,\n",
              " 'based': 78,\n",
              " 'cover': 79,\n",
              " 'art': 80,\n",
              " 'blurbs': 81,\n",
              " 'pedestrian': 82,\n",
              " 'dennis': 83,\n",
              " 'hopper': 84,\n",
              " 'game': 85,\n",
              " 'richard': 86,\n",
              " 'grieco': 87,\n",
              " 'add': 88,\n",
              " 'significant': 89,\n",
              " 'their': 90,\n",
              " 'resumes': 91,\n",
              " 'although': 92,\n",
              " 'direction': 93,\n",
              " 'half': 94,\n",
              " 'bad': 95,\n",
              " 'dialogue': 96,\n",
              " 'will': 97,\n",
              " 'leave': 98,\n",
              " 'grimacing': 99,\n",
              " 'wonder': 100,\n",
              " 'at': 101,\n",
              " 'its': 102,\n",
              " 'conceit': 103,\n",
              " 'storytelling': 104,\n",
              " 'worst': 105,\n",
              " 'tension': 106,\n",
              " 'suspense': 107,\n",
              " 'dread': 108,\n",
              " 'fear': 109,\n",
              " 'empathy': 110,\n",
              " 'catharsis': 111,\n",
              " 'few': 112,\n",
              " 'attractive': 113,\n",
              " 'often': 114,\n",
              " 'nude': 115,\n",
              " 'females': 116,\n",
              " 'spice': 117,\n",
              " 'up': 118,\n",
              " 'boredom': 119,\n",
              " 'but': 120,\n",
              " 'definitely': 121,\n",
              " 'best': 122,\n",
              " 'seen': 123,\n",
              " 'as': 124,\n",
              " 'trailer': 125,\n",
              " 'feel': 126,\n",
              " 'sorry': 127,\n",
              " 'guy': 128,\n",
              " 'who': 129,\n",
              " 'greenlighted': 130,\n",
              " 'thing': 131,\n",
              " 'late': 132,\n",
              " 'night': 133,\n",
              " 'zoned': 134,\n",
              " 'out': 135,\n",
              " 'viewing': 136,\n",
              " 'only': 137,\n",
              " 'been': 138,\n",
              " 'warned': 139,\n",
              " 'joseph': 140,\n",
              " 'brady': 141,\n",
              " 'clarence': 142,\n",
              " 'doolittle': 143,\n",
              " 'are': 144,\n",
              " 'two': 145,\n",
              " 'sailors': 146,\n",
              " 'four': 147,\n",
              " 'day': 148,\n",
              " 'shore': 149,\n",
              " 'in': 150,\n",
              " 'hollywood': 151,\n",
              " 'joe': 152,\n",
              " 'knows': 153,\n",
              " 'everything': 154,\n",
              " 'about': 155,\n",
              " 'girls': 156,\n",
              " 'can': 157,\n",
              " 't': 158,\n",
              " 'wait': 159,\n",
              " 'see': 160,\n",
              " 'lola': 161,\n",
              " 'while': 162,\n",
              " 'shyer': 163,\n",
              " 'needs': 164,\n",
              " 'some': 165,\n",
              " 'advice': 166,\n",
              " 'his': 167,\n",
              " 'buddy': 168,\n",
              " 'how': 169,\n",
              " 'meet': 170,\n",
              " 'they': 171,\n",
              " 'run': 172,\n",
              " 'into': 173,\n",
              " 'little': 174,\n",
              " 'boy': 175,\n",
              " 'donald': 176,\n",
              " 'martin': 177,\n",
              " 'has': 178,\n",
              " 'ran': 179,\n",
              " 'away': 180,\n",
              " 'order': 181,\n",
              " 'join': 182,\n",
              " 'navy': 183,\n",
              " 'take': 184,\n",
              " 'him': 185,\n",
              " 'home': 186,\n",
              " 'beautiful': 187,\n",
              " 'aunt': 188,\n",
              " 'susan': 189,\n",
              " 'wants': 190,\n",
              " 'be': 191,\n",
              " 'singer': 192,\n",
              " 'susie': 193,\n",
              " 'girl': 194,\n",
              " 'shyness': 195,\n",
              " 'gets': 196,\n",
              " 'way': 197,\n",
              " 'he': 198,\n",
              " 'doesn': 199,\n",
              " 'shy': 200,\n",
              " 'waitress': 201,\n",
              " 'comes': 202,\n",
              " 'brooklyn': 203,\n",
              " 'like': 204,\n",
              " 'does': 205,\n",
              " 'soon': 206,\n",
              " 'notices': 207,\n",
              " 's': 208,\n",
              " 'love': 209,\n",
              " 'boys': 210,\n",
              " 'fix': 211,\n",
              " 'when': 212,\n",
              " 'lie': 213,\n",
              " 'meeting': 214,\n",
              " 'big': 215,\n",
              " 'time': 216,\n",
              " 'music': 217,\n",
              " 'producer': 218,\n",
              " 'don': 219,\n",
              " 'even': 220,\n",
              " 'know': 221,\n",
              " 'feelings': 222,\n",
              " 'george': 223,\n",
              " 'sidney': 224,\n",
              " 'anchors': 225,\n",
              " 'aweigh': 226,\n",
              " 'musical': 227,\n",
              " 'comedy': 228,\n",
              " 'gene': 229,\n",
              " 'kelly': 230,\n",
              " 'top': 231,\n",
              " 'notch': 232,\n",
              " 'once': 233,\n",
              " 'again': 234,\n",
              " 'singing': 235,\n",
              " 'dancing': 236,\n",
              " 'routines': 237,\n",
              " 'frank': 238,\n",
              " 'sinatra': 239,\n",
              " 'terrific': 240,\n",
              " 'isn': 241,\n",
              " 'first': 242,\n",
              " 'that': 243,\n",
              " 'mind': 244,\n",
              " 'plays': 245,\n",
              " 'part': 246,\n",
              " 'well': 247,\n",
              " 'kathryn': 248,\n",
              " 'grayson': 249,\n",
              " 'fantastic': 250,\n",
              " 'abbott': 251,\n",
              " 'sadly': 252,\n",
              " 'lost': 253,\n",
              " 'gifted': 254,\n",
              " 'actress': 255,\n",
              " 'operatic': 256,\n",
              " 'soprano': 257,\n",
              " 'last': 258,\n",
              " 'month': 259,\n",
              " 'age': 260,\n",
              " 'year': 261,\n",
              " 'old': 262,\n",
              " 'dean': 263,\n",
              " 'stockwell': 264,\n",
              " 'amazing': 265,\n",
              " 'job': 266,\n",
              " 'fellow': 267,\n",
              " 'wanting': 268,\n",
              " 'become': 269,\n",
              " 'sailor': 270,\n",
              " 'jose': 271,\n",
              " 'iturbi': 272,\n",
              " 'performing': 273,\n",
              " 'himself': 274,\n",
              " 'magic': 275,\n",
              " 'piano': 276,\n",
              " 'edgar': 277,\n",
              " 'kennedy': 278,\n",
              " 'chief': 279,\n",
              " 'police': 280,\n",
              " 'station': 281,\n",
              " 'sara': 282,\n",
              " 'berner': 283,\n",
              " 'voice': 284,\n",
              " 'jerry': 285,\n",
              " 'mouse': 286,\n",
              " 'there': 287,\n",
              " 'lot': 288,\n",
              " 'stuff': 289,\n",
              " 'movie': 290,\n",
              " 'numbers': 291,\n",
              " 'look': 292,\n",
              " 'hate': 293,\n",
              " 'so': 294,\n",
              " 'energetic': 295,\n",
              " 'knew': 296,\n",
              " 'quite': 297,\n",
              " 'funny': 298,\n",
              " 'nice': 299,\n",
              " 'moment': 300,\n",
              " 'sings': 301,\n",
              " 'brahms': 302,\n",
              " 'lullaby': 303,\n",
              " 'lovely': 304,\n",
              " 'listen': 305,\n",
              " 'tango': 306,\n",
              " 'jealousy': 307,\n",
              " 'most': 308,\n",
              " 'memorable': 309,\n",
              " 'sequence': 310,\n",
              " 'one': 311,\n",
              " 'takes': 312,\n",
              " 'animated': 313,\n",
              " 'fantasy': 314,\n",
              " 'dances': 315,\n",
              " 'also': 316,\n",
              " 'tom': 317,\n",
              " 'cat': 318,\n",
              " 'butler': 319,\n",
              " 'originally': 320,\n",
              " 'asked': 321,\n",
              " 'mickey': 322,\n",
              " 'refused': 323,\n",
              " 'was': 324,\n",
              " 'nominated': 325,\n",
              " 'five': 326,\n",
              " 'oscars': 327,\n",
              " 'georgie': 328,\n",
              " 'stoll': 329,\n",
              " 'got': 330,\n",
              " 'original': 331,\n",
              " 'score': 332,\n",
              " 'high': 333,\n",
              " 'class': 334,\n",
              " 'entertainment': 335,\n",
              " 'trouble': 336,\n",
              " 'your': 337,\n",
              " 'watching': 338,\n",
              " 'numerous': 339,\n",
              " 'alternate': 340,\n",
              " 'titles': 341,\n",
              " 'generally': 342,\n",
              " 'means': 343,\n",
              " 'tried': 344,\n",
              " 'retried': 345,\n",
              " 'hide': 346,\n",
              " 'turkey': 347,\n",
              " 'various': 348,\n",
              " 'markets': 349,\n",
              " 'such': 350,\n",
              " 'brain': 351,\n",
              " 'machine': 352,\n",
              " 'which': 353,\n",
              " 'seven': 354,\n",
              " 'different': 355,\n",
              " 'super': 356,\n",
              " 'secret': 357,\n",
              " 'government': 358,\n",
              " 'project': 359,\n",
              " 'suppose': 360,\n",
              " 'able': 361,\n",
              " 'use': 362,\n",
              " 'computer': 363,\n",
              " 'read': 364,\n",
              " 'instead': 365,\n",
              " 'drives': 366,\n",
              " 'kill': 367,\n",
              " 'each': 368,\n",
              " 'other': 369,\n",
              " 'or': 370,\n",
              " 'themselves': 371,\n",
              " 'something': 372,\n",
              " 'filled': 373,\n",
              " 'b': 374,\n",
              " 'level': 375,\n",
              " 'tv': 376,\n",
              " 'actors': 377,\n",
              " 'sitting': 378,\n",
              " 'paneled': 379,\n",
              " 'room': 380,\n",
              " 'lawn': 381,\n",
              " 'chairs': 382,\n",
              " 'trying': 383,\n",
              " 'act': 384,\n",
              " 'script': 385,\n",
              " 'makes': 386,\n",
              " 'almost': 387,\n",
              " 'sense': 388,\n",
              " 'untastey': 389,\n",
              " 'avoid': 390,\n",
              " 'by': 391,\n",
              " 'far': 392,\n",
              " 'absolute': 393,\n",
              " 'years': 394,\n",
              " 'saw': 395,\n",
              " 'michael': 396,\n",
              " 'madsen': 397,\n",
              " 'figured': 398,\n",
              " 'couldn': 399,\n",
              " 'too': 400,\n",
              " 'since': 401,\n",
              " 'pretty': 402,\n",
              " 'decent': 403,\n",
              " 'films': 404,\n",
              " 'fair': 405,\n",
              " 'actor': 406,\n",
              " 'wrong': 407,\n",
              " 'waste': 408,\n",
              " 'fast': 409,\n",
              " 'forwarded': 410,\n",
              " 'through': 411,\n",
              " 'percent': 412,\n",
              " 'missed': 413,\n",
              " 'watch': 414,\n",
              " 'bond': 415,\n",
              " 'octopussy': 416,\n",
              " 'still': 417,\n",
              " 'enjoy': 418,\n",
              " 'accept': 419,\n",
              " 'production': 420,\n",
              " 'aren': 421,\n",
              " 'much': 422,\n",
              " 'above': 423,\n",
              " 'sean': 424,\n",
              " 'connery': 425,\n",
              " 'wrinkles': 426,\n",
              " 'forehead': 427,\n",
              " 'beneath': 428,\n",
              " 'an': 429,\n",
              " 'obvious': 430,\n",
              " 'toupee': 431,\n",
              " 'james': 432,\n",
              " 'get': 433,\n",
              " 'past': 434,\n",
              " 'inexperienced': 435,\n",
              " 'basinger': 436,\n",
              " 'weaker': 437,\n",
              " 'largo': 438,\n",
              " 'jolly': 439,\n",
              " 'q': 440,\n",
              " 'learn': 441,\n",
              " 'idiosyncratic': 442,\n",
              " 'barry': 443,\n",
              " 'believe': 444,\n",
              " 'hyperbolic': 445,\n",
              " 'reviews': 446,\n",
              " 'greeted': 447,\n",
              " 'release': 448,\n",
              " 'poker': 449,\n",
              " 'battle': 450,\n",
              " 'video': 451,\n",
              " 'face': 452,\n",
              " 'off': 453,\n",
              " 'them': 454,\n",
              " 'both': 455,\n",
              " 'same': 456,\n",
              " 'yours': 457,\n",
              " 'never': 458,\n",
              " 'say': 459,\n",
              " 'more': 460,\n",
              " 'probably': 461,\n",
              " 'my': 462,\n",
              " 'son': 463,\n",
              " 'yes': 464,\n",
              " 'howling': 465,\n",
              " 'classic': 466,\n",
              " 'rather': 467,\n",
              " 'werewolf': 468,\n",
              " 'admit': 469,\n",
              " 'started': 470,\n",
              " 'slowly': 471,\n",
              " 'gained': 472,\n",
              " 'momentum': 473,\n",
              " 'along': 474,\n",
              " 'finish': 475,\n",
              " 'anchorwoman': 476,\n",
              " 'changed': 477,\n",
              " 'cute': 478,\n",
              " 'gunned': 479,\n",
              " 'down': 480,\n",
              " 'camera': 481,\n",
              " 'made': 482,\n",
              " 'entertaining': 483,\n",
              " 'horror': 484,\n",
              " 'sure': 485,\n",
              " 'forget': 486,\n",
              " 'all': 487,\n",
              " 'oh': 488,\n",
              " 'anchor': 489,\n",
              " 'woman': 490,\n",
              " 'her': 491,\n",
              " 'brother': 492,\n",
              " 'find': 493,\n",
              " 'why': 494,\n",
              " 'things': 495,\n",
              " 'went': 496,\n",
              " 'did': 497,\n",
              " 'go': 498,\n",
              " 'cozy': 499,\n",
              " 'retreat': 500,\n",
              " 'transylvania': 501,\n",
              " 'somewhere': 502,\n",
              " 'where': 503,\n",
              " 'must': 504,\n",
              " 'evil': 505,\n",
              " 'magician': 506,\n",
              " 'werewolves': 507,\n",
              " 'christopher': 508,\n",
              " 'lee': 509,\n",
              " 'doing': 510,\n",
              " 'however': 511,\n",
              " 'trivia': 512,\n",
              " 'says': 513,\n",
              " 'had': 514,\n",
              " 'before': 515,\n",
              " 'role': 516,\n",
              " 'could': 517,\n",
              " 'gotten': 518,\n",
              " 'american': 519,\n",
              " 'london': 520,\n",
              " 'hell': 521,\n",
              " 'possible': 522,\n",
              " 'set': 523,\n",
              " 'after': 524,\n",
              " 'heck': 525,\n",
              " 'seem': 526,\n",
              " 'figure': 527,\n",
              " 'except': 528,\n",
              " 'bizarre': 529,\n",
              " 'prolonged': 530,\n",
              " 'sex': 531,\n",
              " 'scene': 532,\n",
              " 'fact': 533,\n",
              " 'death': 534,\n",
              " 'me': 535,\n",
              " 'gal': 536,\n",
              " 'talking': 537,\n",
              " 'loudly': 538,\n",
              " 'dude': 539,\n",
              " 'ear': 540,\n",
              " 'bleeding': 541,\n",
              " 'may': 542,\n",
              " 'am': 543,\n",
              " 'harsh': 544,\n",
              " 'absolutely': 545,\n",
              " 'stunned': 546,\n",
              " 'enough': 547,\n",
              " 'ask': 548,\n",
              " 'greatly': 549,\n",
              " 'exaggerated': 550,\n",
              " 'silly': 551,\n",
              " 'despite': 552,\n",
              " 'creepy': 553,\n",
              " 'scenes': 554,\n",
              " 'seriously': 555,\n",
              " 'ass': 556,\n",
              " 'stupid': 557,\n",
              " 'story': 558,\n",
              " 'actually': 559,\n",
              " 'deep': 560,\n",
              " 'investigating': 561,\n",
              " 'kayako': 562,\n",
              " 'found': 563,\n",
              " 'she': 564,\n",
              " 'mother': 565,\n",
              " 'miraculously': 566,\n",
              " 'speaks': 567,\n",
              " 'english': 568,\n",
              " 'exorcist': 569,\n",
              " 'fed': 570,\n",
              " 'spirits': 571,\n",
              " 'daughter': 572,\n",
              " 'yeap': 573,\n",
              " 'ok': 574,\n",
              " 'ordinary': 575,\n",
              " 'housewife': 576,\n",
              " 'affair': 577,\n",
              " 'bloke': 578,\n",
              " 'herself': 579,\n",
              " 'dead': 580,\n",
              " 'because': 581,\n",
              " 'rage': 582,\n",
              " 'became': 583,\n",
              " 'vengeful': 584,\n",
              " 'spirit': 585,\n",
              " 'kills': 586,\n",
              " 'anyone': 587,\n",
              " 'enters': 588,\n",
              " 'house': 589,\n",
              " 'acceotable': 590,\n",
              " 'killings': 591,\n",
              " 'began': 592,\n",
              " 'stretch': 593,\n",
              " 'opportunity': 594,\n",
              " 'travel': 595,\n",
              " 'throughout': 596,\n",
              " 'tokyo': 597,\n",
              " 'victims': 598,\n",
              " 'were': 599,\n",
              " 'travelling': 600,\n",
              " 'weren': 601,\n",
              " 'struck': 602,\n",
              " 'hard': 603,\n",
              " 'ghost': 604,\n",
              " 'country': 605,\n",
              " 'without': 606,\n",
              " 'paying': 607,\n",
              " 'public': 608,\n",
              " 'transport': 609,\n",
              " 'fares': 610,\n",
              " 'wouldn': 611,\n",
              " 'being': 612,\n",
              " 'snorts': 613,\n",
              " 'crown': 614,\n",
              " 'depicted': 615,\n",
              " 'very': 616,\n",
              " 'ju': 617,\n",
              " 'grudge': 618,\n",
              " 'than': 619,\n",
              " 'trash': 620,\n",
              " 'spectre': 621,\n",
              " 'truly': 622,\n",
              " 'enjoys': 623,\n",
              " 'felt': 624,\n",
              " 'mission': 625,\n",
              " 'worse': 626,\n",
              " 'viewer': 627,\n",
              " 'coming': 628,\n",
              " 'forms': 629,\n",
              " 'large': 630,\n",
              " 'strands': 631,\n",
              " 'hair': 632,\n",
              " 'power': 633,\n",
              " 'dun': 634,\n",
              " 'liked': 635,\n",
              " 'movies': 636,\n",
              " 'depicting': 637,\n",
              " 'ghosts': 638,\n",
              " 'monsters': 639,\n",
              " 'cause': 640,\n",
              " 'overall': 641,\n",
              " 'results': 642,\n",
              " 'plain': 643,\n",
              " 'storyline': 644,\n",
              " 'less': 645,\n",
              " 'exaggeration': 646,\n",
              " 'would': 647,\n",
              " 'oppenheimer': 648,\n",
              " 'brilliant': 649,\n",
              " 'series': 650,\n",
              " 'finest': 651,\n",
              " 'offerings': 652,\n",
              " 'ever': 653,\n",
              " 'pbs': 654,\n",
              " 'david': 655,\n",
              " 'suchet': 656,\n",
              " 'particularly': 657,\n",
              " 'effective': 658,\n",
              " 'edward': 659,\n",
              " 'teller': 660,\n",
              " 'recall': 661,\n",
              " 'conception': 662,\n",
              " 'spectacularly': 663,\n",
              " 'reason': 664,\n",
              " 'rate': 665,\n",
              " 'full': 666,\n",
              " 'low': 667,\n",
              " 'budget': 668,\n",
              " 'areas': 669,\n",
              " 'actual': 670,\n",
              " 'content': 671,\n",
              " 'recollection': 672,\n",
              " 'miniseries': 673,\n",
              " 'released': 674,\n",
              " 'uk': 675,\n",
              " 'july': 676,\n",
              " 'st': 677,\n",
              " 'region': 678,\n",
              " 'pal': 679,\n",
              " 'ntsc': 680,\n",
              " 'offing': 681,\n",
              " 'universal': 682,\n",
              " 'player': 683,\n",
              " 'us': 684,\n",
              " 'right': 685,\n",
              " 'amazon': 686,\n",
              " 'http': 687,\n",
              " 'tinyurl': 688,\n",
              " 'com': 689,\n",
              " 'znyyq': 690,\n",
              " 'huzzah': 691,\n",
              " 'rating': 692,\n",
              " 'mini': 693,\n",
              " 'approached': 694,\n",
              " 'aware': 695,\n",
              " 'six': 696,\n",
              " 'months': 697,\n",
              " 'sci': 698,\n",
              " 'fi': 699,\n",
              " 'channel': 700,\n",
              " 'continued': 701,\n",
              " 'pepper': 702,\n",
              " 'shows': 703,\n",
              " 'bg': 704,\n",
              " 'ads': 705,\n",
              " 'confess': 706,\n",
              " 'growing': 707,\n",
              " 'unease': 708,\n",
              " 'learned': 709,\n",
              " 'work': 710,\n",
              " 'cinematic': 711,\n",
              " 'stood': 712,\n",
              " 'test': 713,\n",
              " 'regard': 714,\n",
              " 'battlestar': 715,\n",
              " 'galactica': 716,\n",
              " 'remember': 717,\n",
              " 'chromium': 718,\n",
              " 'warriors': 719,\n",
              " 'oscillating': 720,\n",
              " 'red': 721,\n",
              " 'light': 722,\n",
              " 'visor': 723,\n",
              " 'others': 724,\n",
              " 'fondness': 725,\n",
              " 'held': 726,\n",
              " 'special': 727,\n",
              " 'effects': 728,\n",
              " 'evolutionary': 729,\n",
              " 'many': 730,\n",
              " 'state': 731,\n",
              " 'during': 732,\n",
              " 'especially': 733,\n",
              " 'those': 734,\n",
              " 'television': 735,\n",
              " 'memories': 736,\n",
              " 'resolve': 737,\n",
              " 'around': 738,\n",
              " 'arc': 739,\n",
              " 'relationships': 740,\n",
              " 'helped': 741,\n",
              " 'overcome': 742,\n",
              " 'challenges': 743,\n",
              " 'faced': 744,\n",
              " 'frankly': 745,\n",
              " 'latter': 746,\n",
              " 'group': 747,\n",
              " 'core': 748,\n",
              " 'pulled': 749,\n",
              " 'together': 750,\n",
              " 'save': 751,\n",
              " 'another': 752,\n",
              " 'empire': 753,\n",
              " 'cylons': 754,\n",
              " 'gain': 755,\n",
              " 'extermination': 756,\n",
              " 'human': 757,\n",
              " 'race': 758,\n",
              " 'yet': 759,\n",
              " 'base': 760,\n",
              " 'stars': 761,\n",
              " 'swirling': 762,\n",
              " 'men': 763,\n",
              " 'women': 764,\n",
              " 'came': 765,\n",
              " 'enemy': 766,\n",
              " 'virtually': 767,\n",
              " 'unlimited': 768,\n",
              " 'resources': 769,\n",
              " 'somehow': 770,\n",
              " 'managed': 771,\n",
              " 'survive': 772,\n",
              " 'until': 773,\n",
              " 'next': 774,\n",
              " 'didn': 775,\n",
              " 'technology': 776,\n",
              " 'fire': 777,\n",
              " 'survived': 778,\n",
              " 'cared': 779,\n",
              " 'trusted': 780,\n",
              " 'flaws': 781,\n",
              " 'times': 782,\n",
              " 'sappy': 783,\n",
              " 'care': 784,\n",
              " 'writers': 785,\n",
              " 'current': 786,\n",
              " 'rendition': 787,\n",
              " 'seemed': 788,\n",
              " 'understand': 789,\n",
              " 'ways': 790,\n",
              " 'took': 791,\n",
              " 'least': 792,\n",
              " 'character': 793,\n",
              " 'names': 794,\n",
              " 'crafted': 795,\n",
              " 'called': 796,\n",
              " 'reinvention': 797,\n",
              " 'science': 798,\n",
              " 'fiction': 799,\n",
              " 'goal': 800,\n",
              " 'judged': 801,\n",
              " 'accomplished': 802,\n",
              " 'failure': 803,\n",
              " 'derivitive': 804,\n",
              " 'endeavors': 805,\n",
              " 'long': 806,\n",
              " 'borrows': 807,\n",
              " 'liberally': 808,\n",
              " 'tng': 809,\n",
              " 'ds': 810,\n",
              " 'babylon': 811,\n",
              " 'battlefield': 812,\n",
              " 'earth': 813,\n",
              " 'unfortunate': 814,\n",
              " 'ronald': 815,\n",
              " 'd': 816,\n",
              " 'moore': 817,\n",
              " 'contributor': 818,\n",
              " 'popular': 819,\n",
              " 'decade': 820,\n",
              " 'contribution': 821,\n",
              " 'hope': 822,\n",
              " 'difficulties': 823,\n",
              " 'appears': 824,\n",
              " 'conflict': 825,\n",
              " 'bridge': 826,\n",
              " 'crew': 827,\n",
              " 'enterprise': 828,\n",
              " 'e': 829,\n",
              " 'inviolable': 830,\n",
              " 'rule': 831,\n",
              " 'roddenberry': 832,\n",
              " 'lived': 833,\n",
              " 'under': 834,\n",
              " 'rules': 835,\n",
              " 'every': 836,\n",
              " 'break': 837,\n",
              " 'longer': 838,\n",
              " 'authority': 839,\n",
              " 'ron': 840,\n",
              " 'seems': 841,\n",
              " 'forgotten': 842,\n",
              " 'lessons': 843,\n",
              " 'acknowledged': 844,\n",
              " 'master': 845,\n",
              " 'writing': 846,\n",
              " 'created': 847,\n",
              " 'dysfuntional': 848,\n",
              " 'cast': 849,\n",
              " 'intent': 850,\n",
              " 'creating': 851,\n",
              " 'besides': 852,\n",
              " 'dysfunctional': 853,\n",
              " 'bit': 854,\n",
              " 'believable': 855,\n",
              " 'military': 856,\n",
              " 'unprovokedly': 857,\n",
              " 'striking': 858,\n",
              " 'superior': 859,\n",
              " 'officer': 860,\n",
              " 'couple': 861,\n",
              " 'days': 862,\n",
              " 'hack': 863,\n",
              " 'execution': 864,\n",
              " 'happened': 865,\n",
              " 'period': 866,\n",
              " 'war': 867,\n",
              " 'remembered': 868,\n",
              " 'earlier': 869,\n",
              " 'penned': 870,\n",
              " 'capt': 871,\n",
              " 'kirk': 872,\n",
              " 'killed': 873,\n",
              " 'alas': 874,\n",
              " 'surfing': 875,\n",
              " 'infomercials': 876,\n",
              " 'sitcoms': 877,\n",
              " 'morning': 878,\n",
              " 'expect': 879,\n",
              " 'rose': 880,\n",
              " 'mcgowan': 881,\n",
              " 'hot': 882,\n",
              " 'performance': 883,\n",
              " 'oscar': 884,\n",
              " 'worthy': 885,\n",
              " 'ups': 886,\n",
              " 'downs': 887,\n",
              " 'twists': 888,\n",
              " 'end': 889,\n",
              " 'honesty': 890,\n",
              " 'awful': 891,\n",
              " 'typical': 892,\n",
              " 'slasher': 893,\n",
              " 'gore': 894,\n",
              " 'nudity': 895,\n",
              " 'real': 896,\n",
              " 'violence': 897,\n",
              " 'acting': 898,\n",
              " 'nightkill': 899,\n",
              " 'robert': 900,\n",
              " 'mitchum': 901,\n",
              " 'weary': 902,\n",
              " 'private': 903,\n",
              " 'eye': 904,\n",
              " 'probing': 905,\n",
              " 'case': 906,\n",
              " 'missing': 907,\n",
              " 'industrialist': 908,\n",
              " 'mike': 909,\n",
              " 'connors': 910,\n",
              " 'hired': 911,\n",
              " 'jaclyn': 912,\n",
              " 'smith': 913,\n",
              " 'anxious': 914,\n",
              " 'wife': 915,\n",
              " 'man': 916,\n",
              " 'fails': 917,\n",
              " 'inform': 918,\n",
              " 'husband': 919,\n",
              " 'whereabouts': 920,\n",
              " 'lover': 921,\n",
              " 'franciscus': 922,\n",
              " 'dispose': 923,\n",
              " 'wealthy': 924,\n",
              " 'hubby': 925,\n",
              " 'rotten': 926,\n",
              " 'mannix': 927,\n",
              " 'goes': 928,\n",
              " 'western': 929,\n",
              " 'monkeys': 930,\n",
              " 'abused': 931,\n",
              " 'models': 932,\n",
              " 'lean': 933,\n",
              " 'against': 934,\n",
              " 'cars': 935,\n",
              " 'constantly': 936,\n",
              " 'upstaged': 937,\n",
              " 'sybil': 938,\n",
              " 'danning': 939,\n",
              " 'giallo': 940,\n",
              " 'style': 941,\n",
              " 'wrap': 942,\n",
              " 'brings': 943,\n",
              " 'whole': 944,\n",
              " 'mess': 945,\n",
              " 'bitter': 946,\n",
              " 'cinema': 947,\n",
              " 'sooooo': 948,\n",
              " 'poor': 949,\n",
              " 'halloween': 950,\n",
              " 'mixed': 951,\n",
              " 'trick': 952,\n",
              " 'treats': 953,\n",
              " 'rated': 954,\n",
              " 'r': 955,\n",
              " 'graphic': 956,\n",
              " 'sexual': 957,\n",
              " 'situations': 958,\n",
              " 'among': 959,\n",
              " 'flock': 960,\n",
              " 'revenge': 961,\n",
              " 'minded': 962,\n",
              " 'action': 963,\n",
              " 'flicks': 964,\n",
              " 'bill': 965,\n",
              " 'vol': 966,\n",
              " 'punisher': 967,\n",
              " 'walking': 968,\n",
              " 'tall': 969,\n",
              " 'works': 970,\n",
              " 'thanks': 971,\n",
              " 'always': 972,\n",
              " 'watchable': 973,\n",
              " 'denzel': 974,\n",
              " 'washington': 975,\n",
              " 'today': 976,\n",
              " 'j': 977,\n",
              " 'quinnell': 978,\n",
              " 'novel': 979,\n",
              " 'filmed': 980,\n",
              " 'scott': 981,\n",
              " 'glenn': 982,\n",
              " 'luck': 983,\n",
              " 'ex': 984,\n",
              " 'mercenary': 985,\n",
              " 'stooped': 986,\n",
              " 'drinking': 987,\n",
              " 'flash': 988,\n",
              " 'jack': 989,\n",
              " 'daniels': 990,\n",
              " 'partner': 991,\n",
              " 'walken': 992,\n",
              " 'offers': 993,\n",
              " 'chance': 994,\n",
              " 'redemption': 995,\n",
              " 'bodyguard': 996,\n",
              " 'dakota': 997,\n",
              " 'fanning': 998,\n",
              " 'mexican': 999,\n",
              " ...}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3568R6pTniq",
        "outputId": "bd449f9c-087c-4408-8c84-c320550ce6ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "234"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.frequencies[40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "P0lMrwqKTniq",
        "outputId": "f89d53fc-a55d-4065-a6ab-b2509434f4c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3500,)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Xn_F2N-cTniq",
        "outputId": "85aed696-095c-472b-b3d6-c2e9043122d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['this', 'movie', 'starts', 'off', 'on', 'the', 'wrong', 'foot', 'and', 'never', 'really', 'gets', 'it', 'going', 'the', 'first', 'scene', 'shows', 'a', 'life', 'flight', 'helicopter', 'landing', 'and', 'just', 'outside', 'the', 'window', 'you', 'can', 'distinctly', 'see', 'mountains', 'in', 'the', 'background', 'for', 'those', 'of', 'you', 'who', 'might', 'not', 'ever', 'have', 'been', 'to', 'houston', 'there', 'is', 'no', 'elevation', 'change', 'the', 'city', 'sits', 'just', 'above', 'sea', 'level', 'and', 'a', 'ft', 'incline', 'is', 'considered', 'a', 'big', 'hill', 'to', 'go', 'along', 'with', 'that', 'scenery', 'any', 'shots', 'outside', 'of', 'the', 'hospital', 'immediately', 'tell', 'the', 'viewer', 'that', 'they', 'are', 'not', 'in', 'houston', 'the', 'trees', 'are', 'all', 'missing', 'leaves', 'or', 'are', 'pine', 'trees', 'neither', 'of', 'which', 'houston', 'has', 'very', 'much', 'of', 'even', 'the', 'hospital', 'itself', 'on', 'the', 'outside', 'is', 'very', 'unbelievable', 'memorial', 'hermann', 'hospital', 'is', 'one', 'of', 'the', 'top', 'hospitals', 'in', 'the', 'united', 'states', 'and', 'sits', 'smack', 'dab', 'in', 'the', 'middle', 'of', 'the', 'medical', 'district', 'just', 'miles', 'from', 'downtown', 'houston', 'yet', 'every', 'outside', 'shot', 'of', 'the', 'hospital', 'makes', 'it', 'appear', 'that', 'the', 'hospital', 'is', 'out', 'in', 'the', 'suburbs', 'or', 'even', 'the', 'countryside', 'it', 'is', 'obvious', 'that', 'whoever', 'was', 'in', 'charge', 'of', 'the', 'actual', 'tropical', 'storm', 'part', 'of', 'the', 'movie', 'skimped', 'out', 'because', 'the', 'numerous', 'shots', 'of', 'radar', 'are', 'all', 'wrong', 'the', 'first', 'radar', 'image', 'in', 'the', 'movie', 'is', 'that', 'of', 'hurrican', 'hugo', 'hitting', 'south', 'carolina', 'we', 'later', 'see', 'kris', 'kristofferson', 'leaving', 'his', 'job', 'and', 'one', 'of', 'his', 'assistants', 'tells', 'him', 'that', 'alison', 'is', 'moving', 'back', 'south', 'across', 'houston', 'yet', 'the', 'radar', 'image', 'he', 'shows', 'has', 'alison', 'clearly', 'moving', 'north', 'off', 'of', 'the', 'gulf', 'of', 'mexico', 'into', 'houston', 'probably', 'the', 'initial', 'landfall', 'of', 'alison', 'as', 'for', 'the', 'acting', 'it', 'isn', 't', 'all', 'that', 'bad', 'jobeth', 'williams', 'kris', 'kristofferson', 'and', 'rick', 'schroder', 'all', 'do', 'a', 'decent', 'job', 'considering', 'that', 'this', 'is', 'a', 'straight', 'to', 'tv', 'movie', 'the', 'plot', 'of', 'the', 'story', 'is', 'decent', 'and', 'the', 'fact', 'that', 'it', 'is', 'based', 'on', 'a', 'true', 'story', 'makes', 'it', 'a', 'bit', 'more', 'entertaining', 'my', 'one', 'problem', 'with', 'the', 'acting', 'is', 'the', 'portrayal', 'of', 'houstonians', 'with', 'big', 'thick', 'southern', 'accents', 'the', 'actors', 'all', 'sound', 'like', 'they', 'are', 'from', 'birmingham', 'alabama', 'and', 'not', 'houston', 'texas', 'the', 'movie', 'gets', 'its', 'point', 'across', 'and', 'to', 'the', 'general', 'audience', 'it', 'does', 'exactly', 'what', 'it', 'is', 'meant', 'to', 'entertain', 'if', 'you', 'are', 'looking', 'for', 'a', 'factual', 'account', 'of', 'what', 'happened', 'to', 'the', 'city', 'of', 'houston', 'in', 'june', 'of', 'then', 'you', 'will', 'be', 'disappointed', 'one', 'thing', 'to', 'keep', 'in', 'mind', 'before', 'viewing', 'this', 'movie', 'is', 'that', 'it', 'is', 'based', 'solely', 'on', 'the', 'evacuation', 'of', 'memorial', 'hermann', 'hospital', 'and', 'not', 'on', 'tropical', 'storm', 'alison', 'and', 'the', 'impact', 'on', 'houston', 'metro', 'itself', 'if', 'you', 'are', 'looking', 'for', 'a', 'factual', 'account', 'of', 'tropical', 'storm', 'alison', 's', 'impact', 'on', 'houston', 'metro', 'might', 'i', 'suggest', 'watching', 'the', 'weather', 'channel', 's', 'storm', 'stories', 'for', 'tropical', 'storm', 'alison', 'out', 'of']\n",
            "['this', 'music', 'is', 'totally', 'out', 'of', 'touch', 'with', 'the', 'film', 'showing', 'up', 'now', 'and', 'then', 'as', 'wagnerian', 'bombast', 'and', 'lone', 'ranger', 'hurry', 'up', 'otherwise', 'nonexistent', 'the', 'acting', 'outside', 'of', 'the', 'two', 'principals', 'is', 'nonexistent', 'it', 'would', 'have', 'been', 'an', 'excellent', 'student', 'film', 'the', 'russian', 'soldiers', 'are', 'just', 'models', 'trying', 'to', 'act', 'the', 'constant', 'interruptions', 'with', 'wow', 'explosive', 'camera', 'angles', 'and', 'monocolor', 'clips', 'of', 'pieces', 'of', 'people', 'were', 'quite', 'irritating', 'but', 'that', 's', 'just', 'a', 'personal', 'feeling', 'the', 'story', 'line', 'isn', 't', 'worse', 'than', 'others', 'actually', 'not', 'worse', 'than', 'most', 'completely', 'ignoring', 'logic', 'and', 'reason', 'and', 'reality', 'at', 'least', 'nobody', 'walked', 'in', 'front', 'of', 'a', 'machine', 'gun', 'for', 'three', 'minutes', 'without', 'being', 'hit', 'the', 'three', 'top', 'level', 'bad', 'guys', 'were', 'campy']\n"
          ]
        }
      ],
      "source": [
        "for i in selection:\n",
        "    print(tokenizer.split_text(X_train[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ_WVxH0Tniq"
      },
      "source": [
        "##¬†Basic Text classifiers\n",
        "\n",
        "Now we have pre-processed and tokenized text ! Let's go for classification. To allow fair and easy comparison we start by a Base class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hhMQT9iZTniq"
      },
      "outputs": [],
      "source": [
        "class BaseTextClassifier:\n",
        "    def predict(self, text: str) -> int:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def predict_dataset(self, X: List[str]) -> List[int]:\n",
        "        return [self.predict(x) for x in X]\n",
        "\n",
        "    def evaluate(self, X: List[str], y: List[int]) -> Dict[str, float]:\n",
        "        predictions = self.predict_dataset(X)\n",
        "        y_array = np.array(y)\n",
        "        accuracy = np.mean(predictions == y_array)\n",
        "        return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul1MFhddTnir"
      },
      "source": [
        "üöß **Question** üöß\n",
        "Propose a a very basic classifier.\n",
        "- Gather counts of \"positive\" and \"negative\" words.\n",
        "- But how do we know if a word is positive or negative ?\n",
        "- We can look at words in the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Uxu79dYhTnis"
      },
      "outputs": [],
      "source": [
        "# Inherit from the Base class and implement a classifier based on counts\n",
        "\n",
        "\n",
        "class CountBasedClassifier(BaseTextClassifier):\n",
        "    def __init__(self, n_classes):\n",
        "        self.n_classes = n_classes\n",
        "        self.tokenizer = WhiteSpaceTokenizer()\n",
        "        self.counts = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tokenizer.fit(X)\n",
        "        # X est le corpus : un ensemble de textes\n",
        "        for i in range(len(X)):\n",
        "            tokens = self.tokenizer.encode(X[i])\n",
        "            # tokens la liste des mots (sous forme d'indices) dans le texte X[i]\n",
        "            for iw in tokens:\n",
        "                if iw == -1:\n",
        "                    continue\n",
        "                key = y[i], iw\n",
        "                if key in self.counts.keys():\n",
        "                    self.counts[key] += 1\n",
        "                else:\n",
        "                    self.counts[key] = 1\n",
        "\n",
        "    def predict(self, text):\n",
        "        wordidx = self.tokenizer.encode(text)\n",
        "        # scores par classe pour le text\n",
        "        scores = np.zeros(self.n_classes)\n",
        "        for i in wordidx:\n",
        "            if i == -1:\n",
        "                continue\n",
        "            for c in range(self.n_classes):\n",
        "                key = c, i\n",
        "                if key in self.counts.keys():\n",
        "                    scores[c] += self.counts[c, i]\n",
        "        return np.argmax(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phaM0x7ATnis",
        "outputId": "b0213654-c098-4c66-9885-0f01343fc023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built a vocabulary of 32830 words.\n"
          ]
        }
      ],
      "source": [
        "classif = CountBasedClassifier(2)\n",
        "classif.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUeYj15_Tnis",
        "outputId": "199020a5-918f-42b0-d080-5a6a7cedb484"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(1)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classif.predict(\"very good\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FxGOfiFTnis",
        "outputId": "2bd3441c-436e-483d-c509-4ba46ccf254d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': np.float64(0.6506666666666666)}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Accuracy \")\n",
        "classif.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3GqSFw-ITnit",
        "outputId": "9cb7a47d-be74-4bb8-8fe9-a0fc55360d55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equilibre entre classe:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float64(0.49333333333333335)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Equilibre entre classe:\")\n",
        "y_test.sum() / len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30j_kIz6Tnit"
      },
      "source": [
        "## Do you know the Zipf Law ?\n",
        "\n",
        "üöß **Question** üöß\n",
        "The tokenizer contains the counts for every words in the training set. Plot the the word counts in descending order.\n",
        "Comment the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kAmnA3VjTnit",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "wc = list(classif.tokenizer.frequencies.values())\n",
        "wc.sort(reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "nZzQ_BBjTnit",
        "outputId": "da7e5b8d-2549-4767-bba3-d764651988be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x31e742710>]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.loglog(wc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PswVyJdiTnit"
      },
      "outputs": [],
      "source": [
        "# Inherit from the Base class and implement a classifier based on counts\n",
        "\n",
        "\n",
        "class ProbaClassifier(BaseTextClassifier):\n",
        "    def __init__(self, n_classes):\n",
        "        self.n_classes = n_classes\n",
        "        # This attribute is not used, but kept for API consistency\n",
        "        self.tokenizer = WhiteSpaceTokenizer()\n",
        "\n",
        "    def get_word_count(self, X, y):\n",
        "        words_count = np.zeros((self.n_classes, self.tokenizer.num_words), dtype=int)\n",
        "        for i in range(len(X)):\n",
        "            tokens = self.tokenizer.encode(X[i])\n",
        "            for w in tokens:\n",
        "                if w != -1:\n",
        "                    words_count[y[i], w] += 1\n",
        "        frequencies = words_count / words_count.sum(axis=1, keepdims=True)\n",
        "        return words_count, frequencies\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tokenizer.fit(X)\n",
        "        word_count, frequencies = self.get_word_count(X, y)\n",
        "        self.frequencies = frequencies\n",
        "        self.words_count = word_count\n",
        "\n",
        "    def predict(self, text: str) -> int:\n",
        "        \"\"\"\n",
        "        Calculate a score for each label by summing\n",
        "        the normalized frequencies of the words in 'text'.\n",
        "        Then choose the label with the highest score.\n",
        "        \"\"\"\n",
        "        global_count = self.words_count.sum(axis=0)\n",
        "        global_freq = global_count / global_count.sum()\n",
        "        words = self.tokenizer.encode(text)\n",
        "        words = np.array([w for w in words if w != -1])\n",
        "        words_count_per_class = self.frequencies[:, words] / global_freq[words]\n",
        "        scores = words_count_per_class.sum(axis=1)\n",
        "        return np.argmax(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Iny5SXTnit",
        "outputId": "43342415-54e2-4064-f353-defebb37adb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built a vocabulary of 32830 words.\n",
            "{'accuracy': np.float64(0.8193333333333334)}\n"
          ]
        }
      ],
      "source": [
        "classifier = ProbaClassifier(2)\n",
        "classifier.fit(X_train, y_train)\n",
        "print(classifier.evaluate(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "SC72fiywTniu",
        "outputId": "619ba76a-80a5-4dc1-c860-d4cb03078ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11910   232  1623 ...     1     1     1]\n"
          ]
        }
      ],
      "source": [
        "print(classifier.words_count.sum(axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IPwRLNNxTniu",
        "outputId": "6c1b8d6a-74e0-4f43-9b0c-3d0fd02573f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eus', 'soient', 'aurait', 'ayons', 'aurais', 'aies', 'eu', 'ayant', '√†', 'fussent', 'mon', 'm', '√©taient', 'e√ªmes', 'mes', 'e√ªt', 'en', 'ma', 'qui', 'l', 'sont', 'aurai', 'eue', 'ayante', 'une', 'seront', '√™tes', 'as', 'son', 'fussiez', 'la', '√©tions', 'je', 'ayants', 'aurons', 'eurent', 'votre', 'ta', 'suis', 'ayantes', 'avait', 'de', 'eusse', '√©t√©e', 'soyez', 'eusses', 'ses', 'ayez', 'y', 'elle', '√©tant', 'aux', 'ils', 'seras', 'sera', '√©tants', 'avez', 'auriez', 'es', 'aie', 'eut', 'avais', 'serions', 'tu', 'c', 'serons', 'vos', 'eues', 'ait', 'te', 'sois', 'aurions', 'serait', '√©t√©es', 'ai', 'avec', 'ont', 'qu', 'eux', 'm√™me', 'serez', 'avions', 'sommes', 'd', 'vous', 'f√ªmes', 'aviez', 'mais', 'nos', '√©t√©', 'pour', 'notre', 'serais', 'eussent', 'dans', 'toi', 'et', 'tes', 'j', 'fusses', 'du', 'fut', 'ou', 'au', '√©tantes', 'un', 'avons', 'e√ªtes', '√©tiez', 'avaient', 'aient', 'f√ªtes', 'ce', 'il', 'sur', 'serai', 'ton', 'seriez', 'que', 'soyons', 'par', 'furent', 'lui', 'ne', 'ces', '√©tait', 'eussiez', 'me', 'aura', 'aurez', 'se', 'fusse', 'f√ªt', 'des', '√©t√©s', 'les', '√©tais', 'fussions', 's', 'auraient', 'eussions', '√©tante', 't', 'est', 'auras', 'le', 'auront', 'moi', 'fus', 'n', 'leur', 'seraient', 'on', 'soit', 'pas', 'sa', 'nous'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/malikchettih/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/malikchettih/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "stop = set(stopwords.words(\"french\"))\n",
        "print(stop)\n",
        "len(stop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xbgZuxHITniu",
        "outputId": "250c38fc-ce9f-46d9-ab81-fc49701edc19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flower\n",
            "flower\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "\n",
        "lem = WordNetLemmatizer()\n",
        "porter = PorterStemmer()\n",
        "print(lem.lemmatize(\"flowers\"))\n",
        "print(porter.stem(\"flowers\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wepwJD-Tniu"
      },
      "source": [
        "## Do you know SciKit-Learn ?\n",
        "\n",
        "üöß **Question** üöß\n",
        "\n",
        "How can we optimize the algorithm?\n",
        "- For the tokenization and/or vectorization ?\n",
        "- For the classifier ? Write you count-based classifier that uses the vectorizer of SKLearn.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-fnsbqRWTniu"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "Xvtrain = vectorizer.fit_transform(X_train).toarray()\n",
        "Xvtest = vectorizer.transform(X_test).toarray()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl2lvhIUf0a0",
        "outputId": "50e58743-c3e2-49c6-98e5-5252b8072565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3500, 32807)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xvtrain.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdGPBhIkTniv"
      },
      "source": [
        "Now we have a \"SKLearn\" dataset,  we can also use all the classifiers we want from this library:\n",
        "- Naive Bayes\n",
        "- Logistic Regression\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZovhsQLjTniv"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "teYVt5YDTniv",
        "outputId": "6276d587-ba9b-4393-dcfd-e005bcc00886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32807,)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xvtrain[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "JbFnf9sTTniw",
        "outputId": "43882c15-8dd6-432c-a2de-5803abe5f8a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200, tol=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=200, tol=0.01)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(max_iter=200, tol=0.01)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classif = LogisticRegression(max_iter=200, tol=1e-2)\n",
        "classif.fit(Xvtrain, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-6p9TiTniw",
        "outputId": "4a48471b-ba97-41dc-e21d-9d8d5b783cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8726666666666667\n"
          ]
        }
      ],
      "source": [
        "y_pred = classif.predict(Xvtest)\n",
        "accuracy = np.mean(y_test == y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SANZlfrJTniw"
      },
      "source": [
        "$$P(y | x ) = \\frac{1}{1+\\exp({w^t x})}$$\n",
        "avec :\n",
        "- x : le vecteur qui contient les comptes de mots\n",
        "- w : un vecteur de param√®tre, de m√™me taille que x\n",
        "Si $x = ( x_i )$,  $x_i$ le compte du mot i, i √©tant l'indice dans le vocabulaire.\n",
        "$$ w^t x = \\sum_i w_i\\times x_i $$\n",
        "\n",
        "Formule de Bayes\n",
        "$$P(y | x ) = \\frac{P(x | y )P( y )}{P( x )}  = \\frac{P(x , y )}{P( x )} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "AEZj3xc0Tniw",
        "outputId": "5c880401-cc97-4774-ac14-0dc0a8ccfb92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8393333333333334\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "classif = MultinomialNB()\n",
        "classif.fit(Xvtrain, y_train)\n",
        "\n",
        "y_pred = classif.predict(Xvtest)\n",
        "accuracy = np.mean(y_test == y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "kgioY5x1Tnix",
        "outputId": "893cf384-1e7c-46b0-a967-a45e5692bdc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.848\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "classif = BernoulliNB()\n",
        "classif.fit(Xvtrain, y_train)\n",
        "\n",
        "y_pred = classif.predict(Xvtest)\n",
        "accuracy = np.mean(y_test == y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "yZtImtFcTnix",
        "outputId": "39e5098d-d368-4d43-89a3-79656f0e1d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.848\n"
          ]
        }
      ],
      "source": [
        "y_pred = classif.predict(Xvtest)\n",
        "accuracy = np.mean(y_test == y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73tYYvKQTnix"
      },
      "source": [
        "# Vectorization and NLP\n",
        "\n",
        "In Machine Learning for supervised classification, many approaches work with vectors. The input to be classified is represented by a vector which is given to the classifier. This input vector gathers a set of numerical features that describes the input. What kind of features can we extract from text ?  \n",
        "The \"easy features\" are what we have done:\n",
        "- Counting words (do we need all the words ?)\n",
        "- Could we use binary features ?\n",
        "- Counting n-grams (why ?)\n",
        "\n",
        "\n",
        "üöß **Question** üöß\n",
        "\n",
        "For instance, take what we did for the logistic regression and provide an interpretation of the model, its decision rule and the parameters ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwsD1P9bTnix"
      },
      "source": [
        "## Bag of words model\n",
        "\n",
        "- We count the number of times each word appears in a text.\n",
        "- We can then represent the text as a vector of counts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsPDC_ocTniy"
      },
      "source": [
        "## Frequency-based vectorization\n",
        "\n",
        "- We can normalize the counts by the total number of words in the text.\n",
        "- This gives us the frequency of each word in the text.\n",
        "- This is called the **term frequency**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7gZSFtiTniy"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "- **Intuition**:\n",
        "  - If a word appears many times in a document, it is important.\n",
        "  - If a word appears in many documents, it is not very informative.\n",
        "  - For instance, the words \"the\", \"and\" appears in many documents.\n",
        "\n",
        "- **TF-IDF**:\n",
        "  - We multiply the term frequency by the inverse document frequency.\n",
        "  - Used a lot for information retrieval.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1w52WVaTniy"
      },
      "source": [
        "### Term Frequency (TF)\n",
        "$$\n",
        "\\text{TF}(t, d) = \\frac{f_{t, d}}{\\sum_{t' \\in d} f_{t', d}}\n",
        "$$\n",
        "Where:\n",
        "- $ f_{t, d} $: Frequency of term $ t $ in document $ d $.\n",
        "- $ \\sum_{t' \\in d} f_{t', d} $: Total number of terms in document $ d $.\n",
        "\n",
        "---\n",
        "\n",
        "### Inverse Document Frequency (IDF)\n",
        "$$\n",
        "\\text{IDF}(t) = \\log\\left(\\frac{N + 1}{\\text{DF}(t) + 1}\\right) + 1\n",
        "$$\n",
        "Where:\n",
        "- $ N $: Total number of documents.\n",
        "- $ \\text{DF}(t) $: Number of documents containing the term $ t $.\n",
        "- Adding $ +1 $ in numerator and denominator prevents division by zero.\n",
        "\n",
        "---\n",
        "\n",
        "### TF-IDF\n",
        "$$\n",
        "\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n",
        "$$\n",
        "\n",
        "\n",
        "üöß **Question** üöß\n",
        "\n",
        "Write a function that computes the TF-IDF matrix from a word count matrix  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WLuOEwAZTniy"
      },
      "outputs": [],
      "source": [
        "def word_count_to_tfidf(word_count_matrix):\n",
        "    # <-- TODO\n",
        "    # Term Frequency (TF)\n",
        "    term_frequencies = word_count_matrix / word_count_matrix.sum(axis=1, keepdims=True)\n",
        "\n",
        "    # Document Frequency (DF)\n",
        "    document_frequencies = np.count_nonzero(word_count_matrix > 0, axis=0)\n",
        "\n",
        "    # Inverse Document Frequency (IDF)\n",
        "    num_documents = word_count_matrix.shape[0]\n",
        "    idf = np.log((num_documents + 1) / (document_frequencies + 1)) + 1\n",
        "\n",
        "    # TF-IDF\n",
        "    tfidf_matrix = term_frequencies * idf\n",
        "    return tfidf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPscSOFuq7vs",
        "outputId": "c210c13c-adfb-4bc5-c234-e28f56d4998a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3500, 32807)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xvtrain.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOjhOB7YTniy"
      },
      "source": [
        "## Application: identifying similar documents\n",
        "\n",
        "- We can use TF-IDF to identify similar documents.\n",
        "- To quickly compare two documents, we can compute the cosine similarity between their TF-IDF vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qSyGaWvATniy"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vec = vectorizer.fit_transform(X.apply(preprocess_text))\n",
        "\n",
        "query = \"boats planes and cars\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPryMi7FTniz"
      },
      "source": [
        "üöß **Question** üöß\n",
        "\n",
        "Find the most similar text in $X$ ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkJoyJ3TtpeU",
        "outputId": "c2d01fb7-45eb-4900-d2ff-0f73b636c04c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              "\twith 4 stored elements and shape (5000, 1)>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qv = vectorizer.transform([\"rabbits\"])\n",
        "similarities = X_vec.dot(qv.T)\n",
        "\n",
        "similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYC_EngbTniz",
        "outputId": "fdb31d14-b774-4e48-ea76-2eecf9fca789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folks at Aardman have done a cool, cute and wild adaptation of their short films of Wallace and Gromit to feature length, as the man and his dog, inventors who seem to have more of the intelligence (or practicality) for the latter. In this case they've invented a machine that can capture all of the bunnies that are eating up the crops all over a quiet English village. In particular for Mrs. Tottington (or 'Totty' for those who are 'intimate'), much to the chagrin of Victor Quartermaine, who just wants to kill all the rabbits with his trust rifle. Wallace and Gromit seem to have success with their machine, but Wallace has a mix-up: a machine he's made to make more food suddenly criss-crosses himself with a rabbit - the curse is on! <br /><br />A lot of this is about as much light-hearted fun that a kid's movie could ask for, but it also tips its hat to the oldest tradition in classic cartoon slapstick: Looney Tunes, which in turn is indebted to much silent comedy and vaudeville. Granted, the Aardman guys (Nick Park and Steve Box) have a bunch more gimmicks and tricks and ingenuity with their material. It's never less than amazing to see how they put the stop motion to use, even when a joke or a gag might be a little on the funny \"ho-ho\" not funny \"ha-ha\" side (a tired criticism but I'll say it). Curse of the Were-Rabbit works so well on all fronts for the audience, in its warped story and sudden dips into exposition (the Golden Bullet story is a doozy), Park and Box and company never lose sight of glee in the material.<br /><br />It's fuzzy and warm-hearted and completely off-the-wall for the kids (even the very youngest will love the adventures and strange gadgets, such as the truck Wallace and Gromit drive around in), and for adults there's little barbs of funky, absurdist tones in the midst of a classic English farce. Only (and I'm probably a minority opinion here) when compared to Chicken Run it's almost a little slight a work- there's less any plot than there is a series of running gags, and of course lots of puns involving bunnies and monsters and carnivals and cheese (and horrible men with egos in their guns like the Fiennes voiced Quartermaine). But when it strikes best, it's one of the most entertaining films of 2005. It gives me a big goofy smile anytime it's on TV.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# print(similarities.shape)\n",
        "bestmatch = np.argsort(similarities.toarray()[:, 0])\n",
        "print(X[bestmatch[-3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbpNyROPTniz",
        "outputId": "76afa18d-6185-46bf-c9d0-7d9ae4618fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "3335                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     This is by far the best stand-up routine I have ever seen. John Leguizamo's one man show tells the supposed story of his life in a barrage of lines and situations. By far better than any other comedy out there.\n",
            "3334                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Hilarious film, I had a great time watching it. The star (Cuneyt Arkin, sometimes credited as Steve Arkin) is a popular actor from Turkey. He has played in lots of tough-guy roles, epic-sword films, and romances. It was fun to see him with an international cast and some real lousy looking pair of gloves. If I remember it was also dubbed in English which made things even more funnier. (kinda like seeing John Wayne speak Turkish).\n",
            "3333                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This Film is the One which you fall in love with. Alfred Hitchcock shall always remain over the top of any directors of his time. The most influential aspects about his films are sheer Simplicity & Gripping Drama. The another best thing about Hitchcock's films is a Definite & Gripping End.<br /><br />Any thing said about \"The Man who knew too much\" is less. The Cinematography, Acting, Dialogs & Camera Works are magnificent in this Movie. The Song \"Que Sera Sera\" at the end shall remain in our memories for life time. The film is so enjoyable from start to end that we never know when it ends. Rarely would Hitchcock include humor in his films, this film has comic scenes which fits in to the movie. <br /><br />This film is absolutely brilliant & as good as Vertigo.\n",
            "3332                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         This is the one major problem with this film, along with a good deal of qu√©becois' biggest movies: Done in a pretentious way by pretentious people.<br /><br />It's really sad, but \"big shots\" movie makers (driving Dodge Stratus...) from this province believes They Got the Thruth, They Know What the Little People Like.<br /><br />We're not a rich province, every time a big movie like this (30 millions?!!?) is made, it's cutting off a lot of others who won't see their movie made because of lack of governmental help. So it generates mediocrity; only movies from \"friends of the family\" are going to be made.<br /><br />I sound angry and I am. I went see Nouvelle-France expecting a journey in the lives of my ancestors, but i found myself stuck in a pool of inconsistencies: french accent (we gotta please our cousins, so f*** our qu√©becois' language)and lack of historical research is only a few. Add a campy love story and the same music score playing again and again and dumb qu√©becois' viewer is gonna open up and ask for more. I'm glad this pretentious piece of s*** didn't do as planned by the Dodge stratus Big Shots... It's gonna help movie makers who aren't in the very restrained \"movie business\" of Qu√©bec.<br /><br />Rent Cruising Bar instead and have a real good time.<br /><br />PS: I'll never forgive them for ruining such an awesome title.\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "4999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     This was a big disappointment for me. I think this is the worst Mastroianni-movie ever made. Cosmatos tries too hard to make this movie a masterpiece and that makes this movie a typical \"art\"-movie. I give 4/10 for this movie.\n",
            "191     The Golden Door is the story of a Sicilian family's journey from the Old World (Italy) to the New World (America). Salvatore, a middle-aged man who hopes for a more fruitful life, persuades his family to leave their homeland behind in Sicily, take the arduous journey across the raging seas, and inhabit a land whose rivers supposedly flow with milk. In short, they believe that by risking everything for the New World their dreams of prosperity will be fulfilled. The imagery of the New World is optimistic, clever and highly imaginative. Silver coins rain from heaven upon Salvatore as he anticipates how prosperous he'll be in the New World; carrots and onions twice the size of human beings are shown being harvested to suggest wealth and health, and rivers of milk are swam in and flow through the minds of those who anticipate what the New World will yield. All of this imagery is surrealistically interwoven with the characters and helps nicely compliment the gritty realism that the story unfolds to the audience. The contrast between this imagery versus the dark reality of the Sicilian people helps provide hope while they're aboard the ship to the New World.<br /><br />The voyage to the New World is shot almost in complete darkness, especially when the seas tempests roar and nearly kill the people within. The dark reality I referred to is the Old World and the journey itself to the New World. The Old World is depicted as somewhat destitute and primitive. This is shown as Salvatore scrambles together to sell what few possessions he has left (donkeys, goats and rabbits) in order to obtain the appropriate clothing he needs to enter the New World. I thought it was rather interesting that these people believed they had to conform to a certain dress code in order to be accepted in the New World; it was almost suggesting that people had to fit a particular stereotype or mold in order to be recognized as morally fit. The most powerful image in the film was when the ship is leaving their homeland and setting sail for the New World. This shot shows an overhead view of a crowd of people who slowly seem to separate from one another, depicting the separation between the Old and New Worlds. This shot also suggested that the people were being torn away from all that was once familiar, wanted to divorce from their previous dark living conditions and were desirous to enter a world that held more promise.<br /><br />As later contrasted to how the New World visually looks, the Old World seems dark and bleak as compared to the bright yet foggy New World. I thought it was particularly interesting that the Statue of Liberty is never shown through the fog at Ellis Island, but is remained hidden. I think this was an intentional directing choice that seemed to negate the purpose of what the Statue of Liberty stands for: \"Give me your poor, your tired, your hungry\" seemed like a joke in regards to what these people had to go through when arriving at the New World. Once they arrived in the Americas, they had to go through rather humiliating tests (i.e. delousing, mathematics, puzzles, etc.) in order to prove themselves as fit for the New World. These tests completely changed the perspectives of the Sicilian people. In particular, Salvatore's mother had the most difficult time subjecting herself to the rules and laws of the New World, feeling more violated than treated with respect. Where their dreams once provided hope and optimism for what the New World would provide, the reality of what the New World required was disparaging and rude. Salvatore doesn't change much other than his attitude towards what he felt the New World would be like versus what the New World actually was seemed disappointing to him. This attitude was shared by mostly everyone who voyaged with him. Their character arcs deal more with a cherished dream being greatly upset and a dark reality that had to be accepted.<br /><br />The film seems to make a strong commentary on preparing oneself to enter a heavenly and civilized society. Cleanliness, marriage and intelligence are prerequisites. Adhering to these rules is to prevent disease, immoral behavior and stupidity from dominating. Perhaps this is a commentary on how America has learned from the failings of other nations and so was purposefully established to secure that these plagues did not infest and destruct. Though the rules seemed rigid, they were there to protect and help the people flourish.\n",
            "1878                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The folks at Aardman have done a cool, cute and wild adaptation of their short films of Wallace and Gromit to feature length, as the man and his dog, inventors who seem to have more of the intelligence (or practicality) for the latter. In this case they've invented a machine that can capture all of the bunnies that are eating up the crops all over a quiet English village. In particular for Mrs. Tottington (or 'Totty' for those who are 'intimate'), much to the chagrin of Victor Quartermaine, who just wants to kill all the rabbits with his trust rifle. Wallace and Gromit seem to have success with their machine, but Wallace has a mix-up: a machine he's made to make more food suddenly criss-crosses himself with a rabbit - the curse is on! <br /><br />A lot of this is about as much light-hearted fun that a kid's movie could ask for, but it also tips its hat to the oldest tradition in classic cartoon slapstick: Looney Tunes, which in turn is indebted to much silent comedy and vaudeville. Granted, the Aardman guys (Nick Park and Steve Box) have a bunch more gimmicks and tricks and ingenuity with their material. It's never less than amazing to see how they put the stop motion to use, even when a joke or a gag might be a little on the funny \"ho-ho\" not funny \"ha-ha\" side (a tired criticism but I'll say it). Curse of the Were-Rabbit works so well on all fronts for the audience, in its warped story and sudden dips into exposition (the Golden Bullet story is a doozy), Park and Box and company never lose sight of glee in the material.<br /><br />It's fuzzy and warm-hearted and completely off-the-wall for the kids (even the very youngest will love the adventures and strange gadgets, such as the truck Wallace and Gromit drive around in), and for adults there's little barbs of funky, absurdist tones in the midst of a classic English farce. Only (and I'm probably a minority opinion here) when compared to Chicken Run it's almost a little slight a work- there's less any plot than there is a series of running gags, and of course lots of puns involving bunnies and monsters and carnivals and cheese (and horrible men with egos in their guns like the Fiennes voiced Quartermaine). But when it strikes best, it's one of the most entertaining films of 2005. It gives me a big goofy smile anytime it's on TV.\n",
            "2001                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              - After their sons are sentenced to life in prison, Adelle (Debbie Reynolds) and Helen (Shirley Winters) begin receiving threatening phone calls because someone fells their sons got off easy. The pair decides to move to California to escape the publicity of the trial and to start a new life. They start a dance school that is soon very successful. One of the students has a rich unmarried father with whom Adelle quickly falls in love. In the meantime, Helen is busy raising rabbits and becoming a little too infatuated with an evangelist on the radio. It's only a mater of time before everything falls apart and the women enter a world of madness and murder.<br /><br />- I can't help but compare What's the Matter with Helen? to Whoever Slew Auntie Roo?, also starring Shelly Winters. Where that movie seemed almost restrained in its presentation of Auntie Roo's madness, there's nothing holding Helen back in this movie. It may take a good deal of the movie's running time, but once she snaps, Helen is one Bad Mad Mutha. You don't want to mess with her. Winters is so delightfully demented that it was impossible for me not to enjoy her performance. I'm not going to spoil the movie, but the things Helen is capable of are totally over-the-top.<br /><br />- As good as Winters is, Reynolds is totally ridiculous in her role as the gold-digging tap dancer. I got the impression that she thought she was in a movie that would get her nominated for some award. This ain't Citizen Kane! Quit acting so serious. Hey, Debbie, don't you realize that you're main purpose is to be a victim of Winters' insanity.<br /><br />- I just love these former-female-stars-in-the-twilight-of-their-career horror movies. What's the Matter with Helen? is as fun as any.\n",
            "4488                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ''Wallace & Gromit in The Curse of the Were-Rabbit'' is the same type of animation and from the same creators of ''Chicken run'', but the story now is other: Wallace, a inventor who loves cheese and his smart dog Gromit who is always helping Wallace in his problems,are trying to keep the rabbits away from everybody's vegetables,since there is in their town, an annual Giant Vegetable Competition. But when Wallace tries an invention he did, to make the rabbits avoids vegetable, the one who is going to be cursed is him. Before watching this movie I didn't knew that these two characters already existed and were famous.I loved Gromit, and I think he is one of the coolest dogs I already saw.<br /><br />aka \"Wallace & Gromit-A Batalha dos Vegetais\" - Brazil\n",
            "Name: review, Length: 5000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X[bestmatch])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ-hcLRCTniz"
      },
      "source": [
        "## Limitations of frequency-based vectorization\n",
        "\n",
        "- Each word is treated independently, regardless of its context.\n",
        "- The order of words is not taken into account.\n",
        "- Semantic information is not captured.\n",
        "- And other ideas of limitations ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "586au2KlTni0"
      },
      "source": [
        "# Word embeddings\n",
        "\n",
        "**A Intuitive example**: Suppose we are interested in classifying texts in 4 categories: \"World\", \"Sports\", \"Business\", \"Sci/Tech\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs2EkTNnTni0"
      },
      "source": [
        "## Word embeddings\n",
        "- We could manually design a vector for each word.\n",
        "- For instance, over the dimensions [World, Sports, Business, Sci/Tech]:\n",
        "  - \"Football\" could be [0, 0.2, 0.8, 0]\n",
        "  - \"Microsoft\" could be [0, 0, 0.5, 0.5]\n",
        "  - \"Olympics\" could be [0.25, 0.75, 0, 0]\n",
        "- But doing this naively would be very inefficient.\n",
        "  - Hard to design the vectors.\n",
        "  - Hard to compute them\n",
        "  - Does not account for the context of the words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucclqCNeTni0"
      },
      "source": [
        "## Learning word embeddings\n",
        "\n",
        "- Instead, we can learn those embeddings from the data!\n",
        "- Same idea than with neural networks: we learn the weights of the embeddings from the data.\n",
        "\n",
        "**In practice**\n",
        "- Set a dimension $d$ for the embeddings (e.g. 100).\n",
        "- For each word, initialize a random vector of size $d$.\n",
        "- Train a model to predict something from the embeddings.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "üöß **Question** üöß\n",
        "\n",
        "Add the necessary code in the following class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ArTShm-Tni0",
        "outputId": "ae4c9edf-e299-4f2d-fa4d-ba72ecdda8ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  6, 18,  1]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.0617,  0.5320, -1.6179],\n",
              "         [ 1.8863,  0.3235,  0.6280],\n",
              "         [-1.4974, -1.4953,  0.7640],\n",
              "         [-1.6527,  0.7259,  0.8158],\n",
              "         [-0.0617,  0.5320, -1.6179]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "emb = nn.Embedding(32000, 3)  # Cr√©ation d'un module, avec initialisation al√©atoire\n",
        "txts = [[1, 0, 6, 18, 1],]\n",
        "txts = torch.LongTensor(txts)\n",
        "print(txts)\n",
        "emb(txts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "auK6mWA9Tni0"
      },
      "outputs": [],
      "source": [
        "class WordEmbeddingClassifier(BaseTextClassifier):\n",
        "    def __init__(self, n_classes, voc_size, d_embed, tokenizer, lr=1e-3, n_epochs=10):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.voc_size = voc_size\n",
        "        self.lr = lr\n",
        "        self.d_embed = d_embed\n",
        "        self.n_epochs = n_epochs\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.embedding = nn.Embedding(voc_size, d_embed)\n",
        "        self.fc = nn.Linear(d_embed, n_classes)  # Output layer for classification\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(\n",
        "            list(self.embedding.parameters()) + list(self.fc.parameters()), lr=self.lr\n",
        "        )\n",
        "\n",
        "        # Tokenize and convert to tensors\n",
        "        X = [self.tokenizer.encode(text) for text in X]\n",
        "        X = [torch.tensor(tokens) for tokens in X]  # Convert to tensors\n",
        "        # X.shape = (n_texts, n_tokens, 100)\n",
        "        y = torch.tensor(y, dtype=torch.long)  # Convert labels to tensor\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in tqdm(range(self.n_epochs)):\n",
        "            epoch_loss = 0.0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            for i, tokens in enumerate(X):\n",
        "\n",
        "                # Get embeddings and mean pooling\n",
        "                embedded = self.embedding(tokens)  # Shape: (n_tokens, d_embed)\n",
        "                pooled = embedded.mean(dim=0)  # Shape: (d_embed,)\n",
        "\n",
        "                # Pass through classification layer\n",
        "                logits = self.fc(pooled.reshape(1, -1))  # Shape: (1, num_classes)\n",
        "\n",
        "                # Compute loss and backpropagate\n",
        "                loss = criterion(logits, y[i].unsqueeze(0))  # Shape: (1,)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{self.n_epochs}, Loss: {epoch_loss/len(X):.4f}\")\n",
        "\n",
        "    def predict(self, text: str) -> int:\n",
        "        tokens = self.tokenizer.encode(text)\n",
        "        tokens = torch.tensor([t for t in tokens if t != -1])  # Ignore invalid tokens\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedded = self.embedding(tokens)  # Shape: (seq_len, d_embed)\n",
        "            pooled = embedded.mean(dim=0)  # Shape: (d_embed,)\n",
        "            logits = self.fc(pooled.unsqueeze(0))  # Shape: (1, num_classes)\n",
        "            predicted_class = logits.argmax(dim=1).item()  # Get class index\n",
        "\n",
        "        return predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "d41b0fe0e10b431d8114ed1435a6791b",
            "22d928d47fd646648d318cf173457154",
            "2bf3410cdfc840e493b056b68f300b3a",
            "9730198887eb4e5596c865f561d8ce26",
            "d7297e8a2a2f40b89d0716ead2f8b7c4",
            "7c9d1eca7a2a4b5faa9b265138611fd4",
            "4e1cd099f2e54bb79652148690b1d8e2",
            "4b306fcec58c480f92ea4b3a6951d74e",
            "1167f5cccef5483590e8cf5762892b4a",
            "101d7c7015574634a4659848f8a206f1",
            "5a1306d143684552b4be0ce8cc337dc9"
          ]
        },
        "id": "GfpEEdC_Tni1",
        "outputId": "064ef270-1fec-4e3e-ff27-e04bdeaed3b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae24d4426c59484b96e578ca3b44dd44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.4524\n",
            "Epoch 2/10, Loss: 0.1217\n",
            "Epoch 3/10, Loss: 0.0199\n",
            "Epoch 4/10, Loss: 0.0024\n",
            "Epoch 5/10, Loss: 0.0003\n",
            "Epoch 6/10, Loss: 0.0000\n",
            "Epoch 7/10, Loss: 0.0000\n",
            "Epoch 8/10, Loss: 0.0000\n",
            "Epoch 9/10, Loss: 0.0000\n",
            "Epoch 10/10, Loss: 0.0000\n",
            "{'accuracy': np.float64(0.878)}\n"
          ]
        }
      ],
      "source": [
        "classifier = WordEmbeddingClassifier(\n",
        "    voc_size=tokenizer.num_words,\n",
        "    n_classes=2,\n",
        "    d_embed=10,\n",
        "    tokenizer=tokenizer,\n",
        "    lr=0.01,\n",
        "    n_epochs=10\n",
        ")\n",
        "\n",
        "classifier.fit(X_train.tolist(), y_train)\n",
        "\n",
        "print(classifier.evaluate(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "pfHG_zuRTni1",
        "outputId": "9ba72cca-d045-4a6c-b772-cef806abfea0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x3b1ef4cd0>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the embedding matrix of a review\n",
        "\n",
        "text = \"a very bad movie i hated this movie.\"\n",
        "tokens = tokenizer.encode(text)\n",
        "tokens = torch.tensor([t for t in tokens if t != -1])  # Ignore invalid tokens\n",
        "\n",
        "with torch.no_grad():\n",
        "    embedded = classifier.embedding(tokens)  # Shape: (seq_len, d_embed)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(embedded.T, cmap=\"viridis\", aspect=\"auto\")\n",
        "plt.xticks(\n",
        "    range(len(tokens)), [tokenizer.id_to_token[t.item()] for t in tokens], rotation=45\n",
        ")\n",
        "plt.ylabel(\"Embedding dimension\")\n",
        "\n",
        "plt.colorbar(label=\"Embedding value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1-wPtcrTni1"
      },
      "source": [
        "## Word embeddings in practice\n",
        "\n",
        "- Word embeddings can be very powerful but costly to learn.\n",
        "- An innovative idea was to pre-train word embeddings on a large corpus.\n",
        "- This is the idea from the paper \"Distributed Representations of Words and Phrases and their Compositionality\" by Mikolov et al. (2013), which introduced the Word2Vec model.\n",
        "-\n",
        "### Word2Vec\n",
        "- Word2Vec is a contrastive learning model.\n",
        "- Key Idea: Words with similar contexts (neighboring words) have similar vector representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QbH_LcFTni2"
      },
      "source": [
        "\n",
        "## Word2Vec: Key Ideas with Math\n",
        "\n",
        "1. **Select a Word and Context**  \n",
        "   - Randomly sample a word $w$ from a document.  \n",
        "   - Define its **positive context** as the words within a window of size $R$ around $w$, excluding $w$ itself:  \n",
        "     $$\n",
        "     \\mathcal{C}_{\\text{pos}} = [w_{i-R}, \\dots, w_{i-1}, w_{i+1}, \\dots, w_{i+R}].\n",
        "     $$\n",
        "\n",
        "2. **Negative Examples**  \n",
        "   - To balance the training, introduce **negative examples** by sampling $2KR$ random words from the vocabulary $\\mathcal{V}$:  \n",
        "     $$\n",
        "     \\mathcal{C}_{\\text{neg}} = \\{c_1, \\dots, c_{2KR}\\}, \\quad c_j \\in \\mathcal{V}.\n",
        "     $$\n",
        "\n",
        "3. **Embedding Words**  \n",
        "   - Represent the target word $w$ as a vector $\\mathbf{v}_w \\in \\mathbb{R}^d$ using an embeddings table $\\mathcal{E}_w$.  \n",
        "   - Similarly, map each word in $\\mathcal{C}_{\\text{pos}}$ and $\\mathcal{C}_{\\text{neg}}$ to vectors:  \n",
        "     $$\n",
        "     \\mathbf{v}_{\\mathcal{C}_{\\text{pos}}} \\in \\mathbb{R}^{2R \\times d}, \\quad \\mathbf{v}_{\\mathcal{C}_{\\text{neg}}} \\in \\mathbb{R}^{2KR \\times d}.\n",
        "     $$\n",
        "\n",
        "4. **Compute Similarity**  \n",
        "   - For each context word $c$ in $\\mathcal{C}_{\\text{pos}} \\cup \\mathcal{C}_{\\text{neg}}$, compute the similarity with $w$ using the dot product:  \n",
        "     $$\n",
        "     s = \\mathbf{v}_c \\cdot \\mathbf{v}_w.\n",
        "     $$  \n",
        "   - Train the model to maximize the similarity between $w$ and the positive context words, and minimize the similarity with the negative context words.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "emiasd-nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "101d7c7015574634a4659848f8a206f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1167f5cccef5483590e8cf5762892b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22d928d47fd646648d318cf173457154": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9d1eca7a2a4b5faa9b265138611fd4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4e1cd099f2e54bb79652148690b1d8e2",
            "value": "100%"
          }
        },
        "2bf3410cdfc840e493b056b68f300b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b306fcec58c480f92ea4b3a6951d74e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1167f5cccef5483590e8cf5762892b4a",
            "value": 2
          }
        },
        "4b306fcec58c480f92ea4b3a6951d74e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1cd099f2e54bb79652148690b1d8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1306d143684552b4be0ce8cc337dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c9d1eca7a2a4b5faa9b265138611fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9730198887eb4e5596c865f561d8ce26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_101d7c7015574634a4659848f8a206f1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5a1306d143684552b4be0ce8cc337dc9",
            "value": "‚Äá2/2‚Äá[00:42&lt;00:00,‚Äá21.66s/it]"
          }
        },
        "d41b0fe0e10b431d8114ed1435a6791b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22d928d47fd646648d318cf173457154",
              "IPY_MODEL_2bf3410cdfc840e493b056b68f300b3a",
              "IPY_MODEL_9730198887eb4e5596c865f561d8ce26"
            ],
            "layout": "IPY_MODEL_d7297e8a2a2f40b89d0716ead2f8b7c4"
          }
        },
        "d7297e8a2a2f40b89d0716ead2f8b7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
